{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is based on a <a href=\"https://www.kaggle.com/c/word2vec-nlp-tutorial/details/part-1-for-beginners-bag-of-words\"> Kaggle Tutorial</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>qHmamQPCAKkia9X0uryA8g</td>\n",
       "      <td>2006-09-23</td>\n",
       "      <td>M8G9Rs21i4euIo3T5gyGOg</td>\n",
       "      <td>4</td>\n",
       "      <td>Are you drunk? Is it around 3am? Are you in do...</td>\n",
       "      <td>review</td>\n",
       "      <td>Xsp1amevfceAqAMjKhZkgA</td>\n",
       "      <td>{u'funny': 0, u'useful': 1, u'cool': 0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>qHmamQPCAKkia9X0uryA8g</td>\n",
       "      <td>2011-04-06</td>\n",
       "      <td>o9HYfNDSACBPRykq8t21PQ</td>\n",
       "      <td>3</td>\n",
       "      <td>OH NO HE DIDN'T.\\n\\nTHE GUY MAKING THE SAUSAGE...</td>\n",
       "      <td>review</td>\n",
       "      <td>mRQzFZMGurB-3bP4CGTNpQ</td>\n",
       "      <td>{u'funny': 3, u'useful': 1, u'cool': 0}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id        date               review_id  stars  \\\n",
       "0  qHmamQPCAKkia9X0uryA8g  2006-09-23  M8G9Rs21i4euIo3T5gyGOg      4   \n",
       "1  qHmamQPCAKkia9X0uryA8g  2011-04-06  o9HYfNDSACBPRykq8t21PQ      3   \n",
       "\n",
       "                                                text    type  \\\n",
       "0  Are you drunk? Is it around 3am? Are you in do...  review   \n",
       "1  OH NO HE DIDN'T.\\n\\nTHE GUY MAKING THE SAUSAGE...  review   \n",
       "\n",
       "                  user_id                                    votes  \n",
       "0  Xsp1amevfceAqAMjKhZkgA  {u'funny': 0, u'useful': 1, u'cool': 0}  \n",
       "1  mRQzFZMGurB-3bP4CGTNpQ  {u'funny': 3, u'useful': 1, u'cool': 0}  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original = pd.read_csv(\"review_final_academic.csv\", index_col = 0)\n",
    "original.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(122657, 30913, 19792)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#All reviews, 5 star reviews, and 1&2 star reviews\n",
    "len (original), len (original[original.stars >4]), len (original[original.stars <3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total # of extreme reviews is 50705, equal to 41% of total.\n"
     ]
    }
   ],
   "source": [
    "extremerevnum = len(original[original.stars >4]) + len (original[original.stars <3])\n",
    "\n",
    "print \"The total # of extreme reviews is %d, equal to %d%% of total.\" % (extremerevnum,(extremerevnum*100.0)/len(original))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, make a new dataframe 'extreme' comprised of those more extreme reviews.\n",
    "Confirm that it has the number of reviews you'd expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This extreme file has 50705 rows before dropping ones with NA values.\n",
      "This extreme file has 50700 rows after dropping ones with NA values.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>122655</th>\n",
       "      <td>Fh2vlptKk8jyedzCDPbXbw</td>\n",
       "      <td>2011-07-04</td>\n",
       "      <td>B0DlRa0upq4RHGFUVWY6xQ</td>\n",
       "      <td>5</td>\n",
       "      <td>My daughter and I got the 2 meals for $30 whic...</td>\n",
       "      <td>review</td>\n",
       "      <td>7TmlplDISrIVy1QVuRcJyA</td>\n",
       "      <td>{u'funny': 1, u'useful': 1, u'cool': 1}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   business_id        date               review_id  stars  \\\n",
       "122655  Fh2vlptKk8jyedzCDPbXbw  2011-07-04  B0DlRa0upq4RHGFUVWY6xQ      5   \n",
       "\n",
       "                                                     text    type  \\\n",
       "122655  My daughter and I got the 2 meals for $30 whic...  review   \n",
       "\n",
       "                       user_id                                    votes  \n",
       "122655  7TmlplDISrIVy1QVuRcJyA  {u'funny': 1, u'useful': 1, u'cool': 1}  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extreme = pd.DataFrame(original[original.stars.isin([1,2,5])])\n",
    "print \"This extreme file has %d rows before dropping ones with NA values.\" % len(extreme)\n",
    "extreme.dropna(inplace = True) #Removes any row with a NA value\n",
    "print \"This extreme file has %d rows after dropping ones with NA values.\" % len(extreme)\n",
    "extreme.tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first review's index is 2, and you can see above that the last index is much higher that 50,699.  Let's fix that so we can iterate over the review text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50699</th>\n",
       "      <td>Fh2vlptKk8jyedzCDPbXbw</td>\n",
       "      <td>2011-07-04</td>\n",
       "      <td>B0DlRa0upq4RHGFUVWY6xQ</td>\n",
       "      <td>5</td>\n",
       "      <td>My daughter and I got the 2 meals for $30 whic...</td>\n",
       "      <td>review</td>\n",
       "      <td>7TmlplDISrIVy1QVuRcJyA</td>\n",
       "      <td>{u'funny': 1, u'useful': 1, u'cool': 1}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  business_id        date               review_id  stars  \\\n",
       "50699  Fh2vlptKk8jyedzCDPbXbw  2011-07-04  B0DlRa0upq4RHGFUVWY6xQ      5   \n",
       "\n",
       "                                                    text    type  \\\n",
       "50699  My daughter and I got the 2 meals for $30 whic...  review   \n",
       "\n",
       "                      user_id                                    votes  \n",
       "50699  7TmlplDISrIVy1QVuRcJyA  {u'funny': 1, u'useful': 1, u'cool': 1}  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extreme.reset_index(inplace = True, drop = True)\n",
    "extreme.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The function to call to clean text.\n",
    "def cleantext(text):\n",
    "    #text = BeautifulSoup(text).get_text()  #This removes html stuff, but not actual links.\n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \", text).lower()  #This removes everything that isn't a letter\n",
    "    return re.sub( '\\s+', ' ', text).strip()  #This removes excess spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goats llama s how many times\n"
     ]
    }
   ],
   "source": [
    "#Test clean text\n",
    "print cleantext(\"Goats     llama7s    how     778::.45  many.times\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're almost ready to clean all the extreme reviews, and put them in a list.\n",
    "First I want to show you that a bunch of them have weblinks, and that those aren't taken out too well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306 [16, 34, 62, 281]\n"
     ]
    }
   ],
   "source": [
    "#Make a list of indices for reviews with web links in them.\n",
    "cats = []\n",
    "for i in xrange(len(extreme)):\n",
    "    if (\"http\" in extreme.text[i]):\n",
    "        cats.append(i)\n",
    "\n",
    "#A lot of the reviews have web-links in them.\n",
    "print len(cats), cats[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: \n",
      "\"Anytime the great saxophonist Philip Greenlief ( http://evandermusic.com/artist_detail.asp?artist_id=117 ) and I play gig, share a bill or even just attend one or the other's concert all the evening's events just become part of the journey to this Top Dog. \\nHe goes for the tops, I like the Brats and a lemonade.\\nThe coda is a donut from King Pin across the street. \\nAwesome.\" \n",
      "\n",
      " Cleaned: \n",
      "'anytime the great saxophonist philip greenlief http evandermusic com artist detail asp artist id and i play gig share a bill or even just attend one or the other s concert all the evening s events just become part of the journey to this top dog he goes for the tops i like the brats and a lemonade the coda is a donut from king pin across the street awesome'\n"
     ]
    }
   ],
   "source": [
    "hockey = extreme.text[62]\n",
    "print \"Original: \\n%r \\n\\n Cleaned: \\n%r\" %(hockey, cleantext(hockey))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Reviews =  50700\n",
      "10000 (19 percent) completed!\n",
      "20000 (39 percent) completed!\n",
      "30000 (59 percent) completed!\n",
      "40000 (78 percent) completed!\n",
      "50000 (98 percent) completed!\n"
     ]
    }
   ],
   "source": [
    "numreviews = len(extreme.text)\n",
    "print \"Total Reviews = \", numreviews\n",
    "\n",
    "clean_reviews = []\n",
    "\n",
    "for i in xrange(numreviews):\n",
    "    if ((i+1)%10000 == 0):\n",
    "        print \"%d (%d percent) completed!\" % ((i+1),(((i+1)*100.0)/numreviews))\n",
    "    clean_reviews.append(cleantext(extreme.text[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's unhappy about one or two of the rows (if we use BeautifulSoup), but this seems not the end of the world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50700\n"
     ]
    }
   ],
   "source": [
    "#Just to double check it's the same length as the extreme dataframe\n",
    "print len(clean_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Add these to the dataframe\n",
    "extreme['clean'] = clean_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  i don't care what other people say... top dog is awesome. if you hate it, then you're obviously not awesome.\n",
      "\n",
      "ps: don't forget to pour on the russian mustard ;)\n",
      "\n",
      "pps: don't order \"hot dog, please\" you'll get booted. it's \"top dog\". get it straight.\n",
      "================================================================================ \n",
      "Cleaned:  i don t care what other people say top dog is awesome if you hate it then you re obviously not awesome ps don t forget to pour on the russian mustard pps don t order hot dog please you ll get booted it s top dog get it straight\n"
     ]
    }
   ],
   "source": [
    "#See!  Clean\n",
    "print \"Original: \", extreme.text[0]\n",
    "print \"=\"*80, \"\\nCleaned: \", extreme.clean[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Train test split\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(extreme.clean, extreme.stars, random_state=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below initialize the \"CountVectorizer\" object (scikit-learn's bag of words tool).\n",
    "\"Analyzer\" is where we can change n-grams (e.g. bi-grams).\n",
    "I modified the stop_words to be \"english\" rather than default of none.\n",
    "The max features of 5000 means we're limiting the bag to the most highly represented 5000 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer = \"word\", tokenizer = None, preprocessor = None,\\\n",
    "                             stop_words = \"english\", max_features = 5000)\n",
    "\n",
    "#Vectorize our extreme reviews (for training)!\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38025L, 5000L)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vectorized.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so it's 38,025 rows (75% of the reviews are used for training) and 5,000 columns (words).\n",
    "Let's do the regression!  (This can take a few minutes on a lil engine.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(X_train_vectorized,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.825562130178\n"
     ]
    }
   ],
   "source": [
    "y_pred = logreg.predict(vectorizer.transform(X_test).toarray())\n",
    "\n",
    "from sklearn import metrics\n",
    "print metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok! so 82.6% isn't bad.  Right?  Maybe we can manage to get TFIDF working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf = TfidfTransformer()\n",
    "X_train_tfidf = tfidf.fit_transform(X_train_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(X_train_tfidf,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, weird but the regression seems to run a lot faster this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.828639053254\n"
     ]
    }
   ],
   "source": [
    "y_pred = logreg.predict(vectorizer.transform(X_test).toarray())\n",
    "\n",
    "from sklearn import metrics\n",
    "print metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so 82.9% with TFIDF isn't much better than 82.6% was."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hey, OMG wait.  I've been asking it to predict 1,2 or 5 stars, right?  So maybe I should pool the 1 and 2 stars as 0 and the 5 stars as 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Make a new 'score' columns where 1 means 5 stars and 0 means few stars.\n",
    "extreme['score'] = map(int,(extreme.stars == 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Redo Train test split (\"random state = 4\" means in same way, so we can compare!) based on score.\n",
    "X_train, X_test, y_train, y_test = train_test_split(extreme.clean, extreme.score, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Probably don't need to redo this, but...\n",
    "X_train = vectorizer.fit_transform(X_train).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, that took about 10 minutes.\n",
    "Now, let's see how good it looks, and then see if TFIDF alters it at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.927968441815\n"
     ]
    }
   ],
   "source": [
    "y_pred = logreg.predict(vectorizer.transform(X_test).toarray())\n",
    "\n",
    "print metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ooh, 92.8 is a little better.  How about TFIDF data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf = TfidfTransformer()\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(X_train_tfidf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.922840236686\n"
     ]
    }
   ],
   "source": [
    "y_pred = logreg.predict(vectorizer.transform(X_test).toarray())\n",
    "\n",
    "print metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "So, TFIDF doesn't appear to help.  It's 92.3% instead of 92.8%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
